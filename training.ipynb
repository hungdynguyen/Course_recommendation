{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb03af7-9921-462e-9a8e-bdf00a044f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Kernel path: /venv/main/bin/python\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.2.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting einops\n",
      "  Using cached einops-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<6.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-5.0.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /venv/main/lib/python3.12/site-packages (from sentence-transformers) (1.2.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /venv/main/lib/python3.12/site-packages (from sentence-transformers) (2.10.0+cu128)\n",
      "Requirement already satisfied: numpy in /venv/main/lib/python3.12/site-packages (from sentence-transformers) (2.4.1)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /venv/main/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.20.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-1.3.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2026.1.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typer-slim in /venv/main/lib/python3.12/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Collecting safetensors>=0.4.3 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /venv/main/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
      "Requirement already satisfied: anyio in /venv/main/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.12.0)\n",
      "Requirement already satisfied: certifi in /venv/main/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /venv/main/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in /venv/main/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /venv/main/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-3.0.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /venv/main/lib/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Using cached multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.13.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.12/site-packages (from accelerate) (7.2.1)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /venv/main/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.6.3)\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /venv/main/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /venv/main/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch>=1.11.0->sentence-transformers) (1.3.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /venv/main/lib/python3.12/site-packages (from typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers) (8.3.1)\n",
      "Using cached sentence_transformers-5.2.2-py3-none-any.whl (494 kB)\n",
      "Using cached transformers-5.0.0-py3-none-any.whl (10.1 MB)\n",
      "Using cached huggingface_hub-1.3.5-py3-none-any.whl (536 kB)\n",
      "Using cached tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached datasets-4.5.0-py3-none-any.whl (515 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Using cached einops-0.8.2-py3-none-any.whl (65 kB)\n",
      "Using cached aiohttp-3.13.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "Using cached multidict-6.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Using cached pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.6 MB)\n",
      "Using cached regex-2026.1.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Using cached pandas-3.0.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (10.9 MB)\n",
      "Using cached scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
      "Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: xxhash, threadpoolctl, scipy, safetensors, regex, pyarrow, propcache, multidict, joblib, fsspec, frozenlist, einops, dill, attrs, aiohappyeyeballs, yarl, scikit-learn, pandas, multiprocess, aiosignal, huggingface-hub, aiohttp, tokenizers, accelerate, transformers, datasets, sentence-transformers\n",
      "\u001b[2K  Attempting uninstall: fsspec[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/27\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.12.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/27\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling fsspec-2025.12.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/27\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.12.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/27\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: huggingface-hub[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m18/27\u001b[0m [multiprocess]\n",
      "\u001b[2K    Found existing installation: huggingface_hub 1.2.3━━━━━━━━\u001b[0m \u001b[32m18/27\u001b[0m [multiprocess]\n",
      "\u001b[2K    Uninstalling huggingface_hub-1.2.3:╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m18/27\u001b[0m [multiprocess]\n",
      "\u001b[2K      Successfully uninstalled huggingface_hub-1.2.3━━━━━━━━━━\u001b[0m \u001b[32m18/27\u001b[0m [multiprocess]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/27\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 attrs-25.4.0 datasets-4.5.0 dill-0.4.0 einops-0.8.2 frozenlist-1.8.0 fsspec-2025.10.0 huggingface-hub-1.3.5 joblib-1.5.3 multidict-6.7.1 multiprocess-0.70.18 pandas-3.0.0 propcache-0.4.1 pyarrow-23.0.0 regex-2026.1.15 safetensors-0.7.0 scikit-learn-1.8.0 scipy-1.17.0 sentence-transformers-5.2.2 threadpoolctl-3.6.0 tokenizers-0.22.2 transformers-5.0.0 xxhash-3.6.0 yarl-1.22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Cài đặt và Import THÀNH CÔNG!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# 1. Kiểm tra xem Python đang chạy ở đâu\n",
    "print(f\"Python Kernel path: {sys.executable}\")\n",
    "\n",
    "# 2. Cài đặt với phiên bản CHÍNH XÁC từ Docker (torch 2.9.1)\n",
    "# Downgrade torchaudio và torchvision về phiên bản tương thích\n",
    "print(\">>> Cài đặt với phiên bản khớp với Docker (torch 2.9.1)...\")\n",
    "packages = [\n",
    "    \"torch==2.9.1\",\n",
    "    \"torchaudio==2.9.1\",\n",
    "    \"torchvision==0.24.1\",  # Phiên bản tương thích với torch 2.9.1\n",
    "    \"sentence-transformers==5.2.0\",\n",
    "    \"transformers==4.57.6\",\n",
    "    \"datasets\",\n",
    "    \"accelerate\", \n",
    "    \"einops\"\n",
    "]\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"] + packages)\n",
    "\n",
    "# 3. Xác nhận phiên bản đã cài\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import sentence_transformers\n",
    "    import torch\n",
    "    import transformers\n",
    "    print(\"\\n✅ Cài đặt và Import THÀNH CÔNG!\")\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"sentence-transformers version: {sentence_transformers.__version__}\")\n",
    "    print(f\"transformers version: {transformers.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\n❌ Vẫn lỗi: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Lỗi: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40333798-bac5-409c-8c3c-5136c6c1037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43e922-e741-45f5-96b4-ae30deb99065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Đang đọc dữ liệu...\n",
      "--- Mẫu dữ liệu đầu tiên ---\n",
      "Query:    Oversee the coordination of music production personnel, including delegating responsibilities for orchestration, music copying, and vocal coaching.\n",
      "Positive: manage musical staff. Assign and manage staff tasks in areas such as scoring, arranging, copying music and vocal coaching.\n",
      "Negative: Supervise the technical layout of musical notation on the staff, ensuring that all symbols and clefs are correctly positioned for score production.\n",
      "--------------------------\n",
      "Tổng số mẫu training: 300\n",
      ">>> Đang tải model Qwen/Qwen3-Embedding-0.6B...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b5ed08656c41dc99cbe88b65141be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Bắt đầu training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e729e35f1814ad4bbbdf4537e924ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96a12a72f8f494a84deed9cd508b219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Training hoàn tất!\n",
      ">>> Lưu model vào ./output_qwen_embedding_finetuned...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ff979d931643ffa62672b1fe216562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Nén thành qwen_embedding_finetuned.zip...\n"
     ]
    }
   ],
   "source": [
    "# --- 0. Cấu hình ---\n",
    "MODEL_ID = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "OUTPUT_PATH = \"./output_qwen_embedding_finetuned\"\n",
    "\n",
    "# --- 1. ĐỌC DỮ LIỆU ---\n",
    "# --- 1. ĐỌC DỮ LIỆU (Đã sửa theo JSON mẫu) ---\n",
    "print(\">>> Đang đọc dữ liệu...\")\n",
    "\n",
    "data_path = 'train_dataset.json'\n",
    "train_examples = []\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"Lỗi: Không tìm thấy file {data_path}.\")\n",
    "    data = []\n",
    "else:\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        # data = data[:300]  # Bỏ comment nếu muốn test nhanh\n",
    "\n",
    "for i, entry in enumerate(data):\n",
    "    # 1. Lấy Query\n",
    "    query = entry.get('query', \"\").strip()\n",
    "\n",
    "    # 2. Xử lý Positive (Sửa lỗi AttributeError)\n",
    "    pos_raw = entry.get('positive', \"\")\n",
    "    \n",
    "   \n",
    "    pos_text = str(pos_raw)\n",
    "\n",
    "    pos_text = pos_text.replace(\"nan nan\", \"\").strip()\n",
    "\n",
    "    if not query or not pos_text:\n",
    "        continue\n",
    "\n",
    "    texts = [query, pos_text]\n",
    "\n",
    "    neg_list = entry.get('negatives', entry.get('hard_negatives', []))\n",
    "\n",
    "    if isinstance(neg_list, list):\n",
    "        for neg in neg_list:\n",
    "            neg_text = \"\"\n",
    "            if isinstance(neg, str):\n",
    "                neg_text = neg.strip()\n",
    "            \n",
    "            if neg_text:\n",
    "                texts.append(neg_text)\n",
    "\n",
    "    # Tạo InputExample\n",
    "    train_examples.append(InputExample(texts=texts))\n",
    "\n",
    "if not train_examples:\n",
    "    raise ValueError(\"Không có dữ liệu training!\")\n",
    "\n",
    "# In thử mẫu đầu tiên để kiểm tra\n",
    "print(f\"--- Mẫu dữ liệu đầu tiên ---\")\n",
    "print(f\"Query:    {train_examples[0].texts[0]}\")\n",
    "print(f\"Positive: {train_examples[0].texts[1]}\")\n",
    "if len(train_examples[0].texts) > 2:\n",
    "    print(f\"Negative: {train_examples[0].texts[2]}\")\n",
    "print(f\"--------------------------\")\n",
    "print(f\"Tổng số mẫu training: {len(train_examples)}\")\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "# --- 2. TẢI MODEL QWEN EMBEDDING ---\n",
    "print(f\">>> Đang tải model {MODEL_ID}...\")\n",
    "\n",
    "# Cấu hình Transformer base\n",
    "word_embedding_model = models.Transformer(\n",
    "    MODEL_ID,\n",
    "    max_seq_length=512,\n",
    "    model_args={\n",
    "        \"trust_remote_code\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# THÊM pooling\n",
    "pooling_model = models.Pooling(\n",
    "    word_embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode=\"mean\"\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "tokenizer = word_embedding_model.tokenizer\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# --- 3. TRAIN ---\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "\n",
    "print(\">>> Bắt đầu training...\")\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=NUM_EPOCHS,\n",
    "    warmup_steps=int(len(train_dataloader) * 0.1),\n",
    "    output_path=OUTPUT_PATH,\n",
    "    show_progress_bar=True,              \n",
    ")\n",
    "\n",
    "print(\">>> Training hoàn tất!\")\n",
    "\n",
    "# --- 4. LƯU MODEL ---\n",
    "print(f\">>> Lưu model vào {OUTPUT_PATH}...\")\n",
    "model.save(OUTPUT_PATH)\n",
    "\n",
    "# --- 5. NÉN FILE ZIP ---\n",
    "zip_filename = \"qwen_embedding_finetuned\"\n",
    "print(f\">>> Nén thành {zip_filename}.zip...\")\n",
    "shutil.make_archive(zip_filename, \"zip\", OUTPUT_PATH)\n",
    "\n",
    "file_size = os.path.getsize(zip_filename + \".zip\") / (1024 * 1024)\n",
    "print(f\"Kích thước file: {file_size:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0506e7d-54f6-4558-8a12-95235c4c5158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
